- Masked polyline
	- 가려져서 안보이는 line을 보완해주기 위한 모듈
	- 모듈을 구현하기 위해서는 temporal이 필요해짐 *반 쯤 포기*
- MapTR v2에 transformer decoder를 붙이기
	- 아직은 transformer decoder까지는 아니고 결과를 MLP태우는 정도
	- 이렇게 하는 이유는 추가적인 refine
	- 추가적으로 pts 쿼리를 선언할 때 지금처럼 따로 선언해서 더해주는게 아니라 먼저 instance query를 선언하고 그 query를 통해 pts query를 MLP로 만들어주도록
		- Instance query를 선언할 때 애초에 embed dimension * 2 로 선언하고 절반은 instance query를 위해, 나머지 절반을 이용하여 pts query들을 MLP로 선언
	- 이건 잘 모르겠음. 결과를 봐야할거 같음 *몇 가지 모델 만들어서 돌려보는 중이신듯*
- 변경된 maptrv2에서 self attention 확인
	- Maptrv2보면 self attention으로 intra instance와 inter instance attention을 모두 사용중 *시간 나면 확인해볼 것*
- BEV, PV segmentation supervision
	- 현재는 auxiliary loss로만 사용하고 있는데 이를 좀 더 발전시킬 수 없을지 *딱히 떠오르는 건 없음*
- Pivot처럼 하되 decoder를 통해 regression된 line의 길이를 이용하여 fixed_distance느낌으로 짧은 라인에는 적은 수의 pts가 할당되도록
	- 이를 위한 query design은 점차 늘려나가는 것이 어렵다고 판단되어 한 번에 많은 쿼리를 선언하고 점점 줄여나가는? *점점? 예측된 길이에 맞는 쿼리로 바로 사용*
	- MapTR 350개의 쿼리라고 하셨는데 그거를 전부 사용하는 것은 train 단계뿐이고 inference단계에서는 선언만 해두고 사용하는 것은 1/7만인 것으로 알고 있음 *직접 한 번 해봐라 세환이형 생각엔 memory가 터지지 않는다면 큰 차이 없을 것*
	- 그런데 그러면 짧은 polyline에도 처음에는 100개의 쿼리가 할당되는 건데 그러면 이상하게 예측되면서 길이가 왜곡되지 않을까?
		- 이를 해결할 어떠한 refine module이 필요함(이걸 위의 decoder로 해결?)  *앞에 부터 일정 thr로 자르겠다 한 번 해봐야알듯 함*
- ScalableMap의 Perspective view converter
	- IPM이라고 생각되어짐
	- 이게 있었으면 하는 이유가 instance를 한 번 묶어줬으면 하는 거였던거 같은데 위에 적어놓음 *코드 나오면 한 번 확인해보기*
- Cross modal하게 되면 Satellite처럼 patch 형태로 떼서 attention함으로써 연산량을 줄인다
- MapVR처럼 형태를 잡아주는 loss?
	- 그런데 MapTR결과 보면 큰 효과가 없을 것으로 예상 *유의미할지 모르겠다(세환이형)*
- 예측된 길이가 너무 긴 경우 나눠서 transformer decoder 적용
	- 병렬로 연산이 가능해지기 때문에 효율적이다 *크게 와닿지는 않음.. 병렬로 하면 좋은건 알겠는데 잘 될까..?*
- line들간에 NMS를 하는 것이 좋지 않을까?
	- 연산 시간이 오래 걸리기 때문에 힘들지 않을까  *DETR-base 모델들이 사용되는 이유가 NMS를 안써서 라고 생각하는데 NMS에 걸리는 시간을 직접적으로 재본 것이 아니라서 확인이 필요함*
- Pix2Map처럼 scene간의 유사도를 이용하여 어떠한 prior를 줄 수 없을까? 같은 느낌 *오늘 대충 설명 듣긴했는데 잘 와닿지 않아서 다음에 다시 부탁드림*
- 최종 결과를 기반으로 heatmap 예측 이후 dice loss를 주고 싶음
	- 그런데 heatmap으로 했을 때 라인의 연결성을 유지시키는것이 쉽지 않다 *크게 중요하게 생각하진 않으시는 듯*



- 내 의견
	- 예상된 라인의 길이 별로 쿼리를 할당하는 것은 제대로 학습이 된다면 나쁘지 않을 것 같은데 문제는 학습이 오래 걸릴 것 같음
		- 학습 초반에는 부정확한 라인을 잡을 수 밖에 없는데 이 때 이 결과에 따른 쿼리 개수 할당으로 인해 오히려 학습이 늦어지지 않을지 우려스러움 *해봐야 앎*
			- 학습 속도를 앞당기기 위한 DN같은 방법을 생각해볼 필요가 있을 듯 함
		- 쿼리를 줄일 때는 MLP?
			- Distance 계산해서 fixed dist같은 느낌으로? *MLP를 어떻게 쓸거냐에 대한 구체적인 생각이 정리되지 않음*
	- Pts 쿼리를 instance query를 통해 선언하는 것은 좋아보임
		- Hybrid query 상위 호환같은 느낌
		- SparseBEV할 때 후반 버전에서 사용했던거 아닌가?
- 이번 plot들을 보면서 든 생각이 Streammapnet에서 주장한 지역이 겹친다라는 문제가 생각보다 큰 것 같음. *괜찮은거 같은데 굳이 Split 사용안하고 val set에서 train set의 지역을 빼는건 어떠냐는 세환이형의 제안*
	- 개인적으로는 Streammapnet에서 제시한 new split으로 한 번 학습해서 plot해보고 싶음
	- 그 이유는 이상한 형태로 예측하는 것 같은 문제점들이 같은 지역의 GT를 한 번 봄으로써 어거지로 정답을 찾으려해서 생기는 문제점일 수도 있다는 생각이 들었음
	- 물론 다른 모델들이 기본 split으로 진행했으니 우리도 그거로 결과를 비교하긴 해야겠지만 좀 더 모델의 기능을 정확히 확인하기 위해서는 new split으로 진행하는 것이 나을거라는 생각

- Refine(BEV segmentation으로 projection하는 느낌?)
	- BEV embedding을 UNet 태우고 기존의 pts는 landmark 느낌으로 놔둠.
	- UNet의 결과에서 landmark인 pts 영역(*가장 가까운?*) 중 제일 prob이 높은 것을 사용. 만약 없으면 pts를 제거할 수도 있음
		- *다른 라인으로 projection될 가능성이 없을까? 거리 제한을 좀 짧게 주면 해결?*
		- 현재 pts는 굉장히 sparse함
		- 이 사이를 매꿔줄 pts가 필요함 *<< 이거 어떻게 한다그랬지?*
			- landmark를 interpolate하는 등..
	- 대신 GT를 좀 더 dense하게 할 예정
		- 짧은 라인에 50개(대충)의 점이 찍혀도 겹치게 선택할테니 상관없어짐
		- *기존의 landmark 역할을 해줄 pts는 GT를 3m 단위로 설정해서 fixed dist하게 학습하도록 가이드를 줘서 sparse하게 학습하고 마지막에 refine할 때는 gt를 dense하게 줘서 좀 더 정확한 위치를 찾아갈 수 있도록 함*
		- 